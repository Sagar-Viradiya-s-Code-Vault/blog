<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Compose Animation, Under The Hood - Part I | Sagar's Blog</title>
<meta name=keywords content="Compose,Animation"><meta name=description content="A deep dive on internals of Compose Animation"><meta name=author content><link rel=canonical href=https://sagarviradiya.dev/posts/compose-animation/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.a687a634d6c61e52258d42cba296d4db963631cd7db074138c1a0e92f3e3902a.css integrity="sha256-poemNNbGHlIljULLopbU25Y2Mc19sHQTjBoOkvPjkCo=" rel="preload stylesheet" as=style><link rel=icon href=https://sagarviradiya.dev/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://sagarviradiya.dev/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://sagarviradiya.dev/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://sagarviradiya.dev/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://sagarviradiya.dev/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="Compose Animation, Under The Hood - Part I"><meta property="og:description" content="A deep dive on internals of Compose Animation"><meta property="og:type" content="article"><meta property="og:url" content="https://sagarviradiya.dev/posts/compose-animation/"><meta property="og:image" content="https://sagarviradiya.dev/images/header.jpeg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-10-07T00:00:00+00:00"><meta property="article:modified_time" content="2024-10-07T00:00:00+00:00"><meta property="og:site_name" content="Sagar's Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://sagarviradiya.dev/images/header.jpeg"><meta name=twitter:title content="Compose Animation, Under The Hood - Part I"><meta name=twitter:description content="A deep dive on internals of Compose Animation"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://sagarviradiya.dev/posts/"},{"@type":"ListItem","position":2,"name":"Compose Animation, Under The Hood - Part I","item":"https://sagarviradiya.dev/posts/compose-animation/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Compose Animation, Under The Hood - Part I","name":"Compose Animation, Under The Hood - Part I","description":"A deep dive on internals of Compose Animation","keywords":["Compose","Animation"],"articleBody":"Context I have been dabbling with Compose Animation API for quite some time. Moving pixels on the screen how you want is such a joy! During this journey, I explored implementing some cool animations, which led to my curiosity about ‚Äúwhat‚Äôs going on behind the scenes?‚Äù¬†It was a perfect opportunity for me to dig inside the internals.\nAfter learning how everything is wired together, I was fascinated. I knew that sharing this with the community was a must, so I gave a talk on this at Droidcon Lisbon 2022. I wanted to share this with a wider audience at Droidcon London this year, too, but unfortunately, my talk didn‚Äôt make it through.\nI decided to write about this and this is the first part of this series. So sit back, grab your favorite drink, and enjoy!\nWhy? First, why is it essential to know the internals of Compose Animation? I also asked the same question when I decided to investigate. There were a couple of convincing reasons.\nEfficient Animation - Animation can lead to performance implications if not implemented efficiently. Things like unnecessary recompositions or frame drops can easily make your UI ugly. Knowledge of surface level API that you consume mostly will help you to at least think about performance implications while implementing complex animation. Choosing the right tool for the Job - Knowing which is a suitable API to implement animation in hand will help you to use the right tool for the right job. Debugging - Something you cannot run away from üòÖ No matter how much attention to detail is given while implementing something, a day will come when you need to investigate what‚Äôs wrong. You can fly through debugging something if you know that thing very well. Compose Animation is no different.¬†Thin wrapper over API - Sometimes you need a thin wrapper over API to consume it how you want. This also unlocks loose coupling with API so that you can swap it with other APIs in the future. Master of one, Jack of none ü§™ - Sometimes you are just curious and want to master one thing. Alright, I hope the above reasons were enough to convince you and you are curious enough to read further üôÇ Let‚Äôs deep dive!\nFollowing is the order in which we will explore animation API internals.\nCompose animation in Nutshell Compose animation Hierarchy Low level Animation API Animatable API (Coroutine based API) Transition API animate*AsState API Compose Animation in Nutshell Animating is nothing but changing values from source to target rapidly for a given duration of animation. In the compose world this would be changing state values that your composable is reading which will cause a re-layout and redraw of your composable (I didn‚Äôt mention recomposition as this is something you don‚Äôt want. More on this later). Let‚Äôs see one example.\nLet‚Äôs say we want to animate from 0 to 1 for 500 ms. In compose this would be a sequence of state changes at a fixed duration for 500 ms.\nAny guesses on how many times the state changes during 500 ms? ü§î\nWell, it depends on the device‚Äôs refresh rate. For a 60 Hz device, each frame gets 16.67 ms. Doing simple math would give us a number of state changes. You just have to divide 500 by 16.67. Which is ~30 times state updates. This increases with the device refresh rate. So for a 90 Hz panel, it would be ~46, and for a 120 Hz panel, it would be ~61.\nThese numbers also go up as the duration of animation. That‚Äôs why it is essential to also know how you are consuming value within composable. You can leverage graphics layer API to avoid executing all three phases of compose during recomposition due to value change. In most cases, you only need re-layout and redraw. In some cases, you can even avoid re-layout (Animating background color). More on graphics layer API in part - II.\nNow we know the high-level concept of animation in Compose let‚Äôs have a quick look at the API hierarchy.\nAPI Hierarchy At a low level, we have Animation API which is the core engine powering animation. Since this is a low-level API you won‚Äôt be dealing with it mostly unless you are writing something from the ground up.¬†On top of Animation, we have two APIs, Animatable and Transition, which leverage the power of coroutines to unlock animating many things either parallelly or sequentially.\nAt a very high level, we have animate*AsState which is a convenient composable wrapper to initiate animation on state change.\nPlease note, this is not a complete hierarchy as we have more high-level APIs such as AnimateVisibility that depend on Transition. I believe understanding APIs in the diagram above unlocks understanding other high-level API so for the scope of this blog I am not covering them. I hope you would be curious at the end and do your homework üòâ\nLet‚Äôs explore the above hierarchy in more detail.\nAnimation API This is the core engine powering Compose animation. API has nothing to do with compose though as this is completely decoupled from compose and essentially you can consume this and come up with your own Animation system. Compose Animation APIs we will see, are built on top of this API.\nAnimation API is stateless. That means it doesn‚Äôt know anything about the current state of animation. It is not responsible for managing things like changing the target if the user interrupts the animation or tracking the current progress of the animation. These are the responsibilities of high-level APIs.\nThis API is a function of time. All it knows is given the playtime of animation what would be the value of animation at a given playtime. A perfect analogy for this would be scrabbling through video playback. You can jump to a specific time in the video and it will give you a frame at that timestamp.\nLet‚Äôs see one example to understand this better. Going back to the same example we saw earlier. We are animating a value from 0 to 1 for 500 ms. If you feed 250 ms to Animation API it will give you the value of animation at that playtime.\nSo Animation API is essentially a function of time. Given a playtime what would be value at that playtime?\nHere is the abstraction.\ninterface Animation\u003cT, V : AnimationVector\u003e { . . . // Returns the value of the animation at the given play time fun getValueFromNanos(playTimeNanos: Long): T . . . } Looking at the abstraction we can see it is a type agnostic. It can animate any value you feed in. That‚Äôs why there is AnimationVector. Which is the type that animation API deals with. It cannot operate on the type of values you provide. For example, If you are animating Color it will convert Color into something called AnimationVector3D(v1: Float, v2: Float, v3: Float) as Color has three dimensions (RGB). Animating Color will then result in animating RGB values.\nNotice returned value is of your original type. It converts back calculated values from AnimationVector to the type you feed in. There for, you need to also provide TwoWayConverter if you are animating your custom type.\nLooking at the abstraction it is quit straightforward.\n/** * [TwoWayConverter] class contains the definition on how to convert from an arbitrary type [T] to a * [AnimationVector], and convert the [AnimationVector] back to the type [T]. This allows animations * to run on any type of objects, e.g. position, rectangle, color, etc. */ public interface TwoWayConverter\u003cT, V : AnimationVector\u003e { /** * Defines how a type [T] should be converted to a Vector type (i.e. [AnimationVector1D], * [AnimationVector2D], [AnimationVector3D] or [AnimationVector4D], depends on the dimensions of * type T). */ public val convertToVector: (T) -\u003e V /** * Defines how to convert a Vector type (i.e. [AnimationVector1D], [AnimationVector2D], * [AnimationVector3D] or [AnimationVector4D], depends on the dimensions of type T) back to type * [T]. */ public val convertFromVector: (V) -\u003e T } Coming back to Animation API, There are two implementations of this. TargetBasedAnimation and DecayAnimation.\nTargetBasedAnimation TargetBasedAnimation animates values to a specific target. If the target is known, in the above example it was 1. As playtime approaches the duration of animation so does the value approaching the target.\nDecayAnimation DecayAnimation animates values where the target is unknown. For example, based on initial fling velocity if we want to move something we don‚Äôt know where it will end up once velocity becomes zero. Animation here decay over a time.\nLet‚Äôs zoom in further. How does Animation API calculate the value at a given playtime? ü§î\nInternally it delegates to AnimationSpec. So real hero doing heavy lifting is not Animation but AnimationSpec. I kinda lied that Animation API powers Compose Animation. Ultimately complex math is in AnimationSpec. Brace yourself for some scary Math! üëª\nFor the scope of this blog, I am going to cover FloatTweenSpec. This is one of the specs you get out of the box. Before we jump into implementation details, let‚Äôs first understand the key concept of FloatTweenSpec\nDuration: This specifies how long the animation will take to complete, typically in milliseconds (ms). Easing: It controls the rate of change of the animation. Common easing functions include linear interpolation, deceleration, acceleration etc. Delay: You can introduce a delay before the animation starts, allowing more control over when the animation begins. Interpolation: At the core of FloatTweenSpec is the interpolation of values from the start to the end over the animation‚Äôs duration. Let‚Äôs see the implementation details and see how it calculates the value.\nThis is not full implementation. I trimmed this to focus on parts we are interested in. You can check full implementation here.\npublic class FloatTweenSpec( public val duration: Int = DefaultDurationMillis, public val delay: Int = 0, private val easing: Easing = FastOutSlowInEasing ) : FloatAnimationSpec { . . . override fun getValueFromNanos( playTimeNanos: Long, initialValue: Float, targetValue: Float, initialVelocity: Float ): Float { val clampedPlayTimeNanos = clampPlayTimeNanos(playTimeNanos) val rawFraction = if (duration == 0) 1f else clampedPlayTimeNanos / durationNanos.toFloat() val fraction = easing.transform(rawFraction) return lerp(initialValue, targetValue, fraction) } . . . } It first calculates how much time has passed (playTime - delayNanos), and clamps this value between 0 and durationNanos. clampedPlayTimeNanos function above, exactly does that. The next step is to compute the fraction of the animation‚Äôs progress (rawFraction = clampedPlayTimeNanos / durationNanos). If provided duration is zero then the animation would stop immediately with target value. Then, it applies the easing function (fraction = easing.transform(rawFraction)) to modify the fraction according to the specified easing curve. Finally, it interpolates between the start and end values using the lerp() function, which performs a linear interpolation between the two values based on the eased fraction. To boildown this, easing functions convert raw fraction of animation progress into a fraction that follows a specific curve. You can read about this in more detail here.\nFollowing are some more built-in specs that you might want to check out. I will leave that up to you to explore üôÇ\nSpringSpec RepeatableSpec InfiniteRepeatableSpec Parting Thoughts That‚Äôs all for this part. I know this would be a bit overwhelming. I would suggest following this blog along with Animation API open within Android Studio or cs.android.com.\nSo far we have just seen a blackbox which is function of time powering Compose animation. I hope this sets a nice foundation for the next part. In the next part we will see how Compose Animation API leverage this blackbox. Stay tuned!\n","wordCount":"1928","inLanguage":"en","image":"https://sagarviradiya.dev/images/header.jpeg","datePublished":"2024-10-07T00:00:00Z","dateModified":"2024-10-07T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://sagarviradiya.dev/posts/compose-animation/"},"publisher":{"@type":"Organization","name":"Sagar's Blog","logo":{"@type":"ImageObject","url":"https://sagarviradiya.dev/%3Clink%20/%20abs%20url%3E"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://sagarviradiya.dev/ accesskey=h title="Sagar Viradiya (Alt + H)"><img src=https://sagarviradiya.dev/apple-touch-icon.png alt aria-label=logo height=35>Sagar Viradiya</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://sagarviradiya.dev/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://sagarviradiya.dev/talks/ title=Talks><span>Talks</span></a></li><li><a href=https://sagarviradiya.dev/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://sagarviradiya.dev/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://sagarviradiya.dev/>Home</a>&nbsp;¬ª&nbsp;<a href=https://sagarviradiya.dev/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Compose Animation, Under The Hood - Part I</h1><div class=post-meta><span title='2024-10-07 00:00:00 +0000 UTC'>October 7, 2024</span>&nbsp;¬∑&nbsp;10 min&nbsp;¬∑&nbsp;1928 words</div></header><figure class=entry-cover><a href=https://sagarviradiya.dev/posts/compose-animation/images/header.jpeg target=_blank rel="noopener noreferrer"><img loading=eager srcset="https://sagarviradiya.dev/posts/compose-animation/images/header_huc53d7ecd18219c2376ab14843c425463_232797_360x0_resize_q75_box.jpeg 360w ,https://sagarviradiya.dev/posts/compose-animation/images/header_huc53d7ecd18219c2376ab14843c425463_232797_480x0_resize_q75_box.jpeg 480w ,https://sagarviradiya.dev/posts/compose-animation/images/header_huc53d7ecd18219c2376ab14843c425463_232797_720x0_resize_q75_box.jpeg 720w ,https://sagarviradiya.dev/posts/compose-animation/images/header_huc53d7ecd18219c2376ab14843c425463_232797_1080x0_resize_q75_box.jpeg 1080w ,https://sagarviradiya.dev/posts/compose-animation/images/header_huc53d7ecd18219c2376ab14843c425463_232797_1500x0_resize_q75_box.jpeg 1500w ,https://sagarviradiya.dev/posts/compose-animation/images/header.jpeg 1792w" sizes="(min-width: 768px) 720px, 100vw" src=https://sagarviradiya.dev/posts/compose-animation/images/header.jpeg alt="[Generated With AI](https://www.bing.com/images/create/generate-header-image-for-blog-explaining-internal/1-66ffb250fccc43f588e2e34db8724eb4?id=JJRlbQKelN%2fMt%2f3JS0rXFw%3d%3d&amp;view=detailv2&amp;idpp=genimg&amp;thId=OIG1.NpAOOqqUxD4ksSM_1iMa&amp;skey=nRgIOQdbVScL_nCqQ1_pUwJdKJObIw0F24OkIDRyqH0&amp;FORM=GCRIDP&amp;mode=overlay)" width=1792 height=1024></a><p><a href="https://www.bing.com/images/create/generate-header-image-for-blog-explaining-internal/1-66ffb250fccc43f588e2e34db8724eb4?id=JJRlbQKelN%2fMt%2f3JS0rXFw%3d%3d&amp;view=detailv2&amp;idpp=genimg&amp;thId=OIG1.NpAOOqqUxD4ksSM_1iMa&amp;skey=nRgIOQdbVScL_nCqQ1_pUwJdKJObIw0F24OkIDRyqH0&amp;FORM=GCRIDP&amp;mode=overlay">Generated With AI</a></p></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#context>Context</a></li><li><a href=#why>Why?</a></li><li><a href=#compose-animation-in-nutshell>Compose Animation in Nutshell</a></li><li><a href=#api-hierarchy>API Hierarchy</a></li><li><a href=#animation-api>Animation API</a><ul><li><a href=#targetbasedanimation>TargetBasedAnimation</a></li><li><a href=#decayanimation>DecayAnimation</a></li></ul></li><li><a href=#parting-thoughts>Parting Thoughts</a></li></ul></nav></div></details></div><div class=post-content><h2 id=context>Context<a hidden class=anchor aria-hidden=true href=#context>#</a></h2><p>I have been dabbling with Compose Animation API for quite some time. Moving pixels on the screen how you want is such a joy! During this journey, I explored implementing some cool animations, which led to my curiosity about ‚Äúwhat‚Äôs going on behind the scenes?‚Äù¬†¬†It was a perfect opportunity for me to dig inside the internals.</p><p>After learning how everything is wired together, I was fascinated. I knew that sharing this with the community was a must, so I gave a talk on this at Droidcon Lisbon 2022. I wanted to share this with a wider audience at Droidcon London this year, too, but unfortunately, my talk didn‚Äôt make it through.</p><p>I decided to write about this and this is the first part of this series. So sit back, grab your favorite drink, and enjoy!</p><h2 id=why>Why?<a hidden class=anchor aria-hidden=true href=#why>#</a></h2><p>First, why is it essential to know the internals of Compose Animation? I also asked the same question when I decided to investigate. There were a couple of convincing reasons.</p><ol><li>Efficient Animation - Animation can lead to performance implications if not implemented efficiently. Things like unnecessary recompositions or frame drops can easily make your UI ugly. Knowledge of surface level API that you consume mostly will help you to at least think about performance implications while implementing complex animation.</li><li>Choosing the right tool for the Job - Knowing which is a suitable API to implement animation in hand will help you to use the right tool for the right job.</li><li>Debugging - Something you cannot run away from üòÖ No matter how much attention to detail is given while implementing something, a day will come when you need to investigate what‚Äôs wrong. You can fly through debugging something if you know that thing very well. Compose Animation is no different.¬†</li><li>Thin wrapper over API - Sometimes you need a thin wrapper over API to consume it how you want. This also unlocks loose coupling with API so that you can swap it with other APIs in the future.</li><li>Master of one, Jack of none ü§™ - Sometimes you are just curious and want to master one thing.</li></ol><p>Alright, I hope the above reasons were enough to convince you and you are curious enough to read further üôÇ Let‚Äôs deep dive!</p><p>Following is the order in which we will explore animation API internals.</p><ol><li>Compose animation in Nutshell</li><li>Compose animation Hierarchy</li><li>Low level Animation API</li><li>Animatable API (Coroutine based API)</li><li>Transition API</li><li><code>animate*AsState</code> API</li></ol><h2 id=compose-animation-in-nutshell>Compose Animation in Nutshell<a hidden class=anchor aria-hidden=true href=#compose-animation-in-nutshell>#</a></h2><p>Animating is nothing but changing values from source to target rapidly for a given duration of animation. In the compose world this would be changing state values that your composable is reading which will cause a re-layout and redraw of your composable (I didn‚Äôt mention recomposition as this is something you don‚Äôt want. More on this later). Let‚Äôs see one example.</p><p>Let‚Äôs say we want to animate from 0 to 1 for 500 ms. In compose this would be a sequence of state changes at a fixed duration for 500 ms.</p><figure><img loading=lazy src=images/animation_in_nutshell.svg></figure><p>Any guesses on how many times the state changes during 500 ms? ü§î</p><p>Well, it depends on the device&rsquo;s refresh rate. For a 60 Hz device, each frame gets 16.67 ms. Doing simple math would give us a number of state changes. You just have to divide 500 by 16.67. Which is ~30 times state updates. This increases with the device refresh rate. So for a 90 Hz panel, it would be ~46, and for a 120 Hz panel, it would be ~61.</p><p>These numbers also go up as the duration of animation. That‚Äôs why it is essential to also know how you are consuming value within composable. You can leverage graphics layer API to avoid executing all three phases of compose during recomposition due to value change. In most cases, you only need re-layout and redraw. In some cases, you can even avoid re-layout (Animating background color). More on graphics layer API in part - II.</p><p>Now we know the high-level concept of animation in Compose let‚Äôs have a quick look at the API hierarchy.</p><h2 id=api-hierarchy>API Hierarchy<a hidden class=anchor aria-hidden=true href=#api-hierarchy>#</a></h2><figure><img loading=lazy src=images/animation_api_hierarchy.svg></figure><p>At a low level, we have Animation API which is the core engine powering animation. Since this is a low-level API you won‚Äôt be dealing with it mostly unless you are writing something from the ground up.¬†</p><p>On top of Animation, we have two APIs, Animatable and Transition, which leverage the power of coroutines to unlock animating many things either parallelly or sequentially.</p><p>At a very high level, we have animate*AsState which is a convenient composable wrapper to initiate animation on state change.</p><p>Please note, this is not a complete hierarchy as we have more high-level APIs such as AnimateVisibility that depend on Transition. I believe understanding APIs in the diagram above unlocks understanding other high-level API so for the scope of this blog I am not covering them. I hope you would be curious at the end and do your homework üòâ</p><p>Let‚Äôs explore the above hierarchy in more detail.</p><h2 id=animation-api>Animation API<a hidden class=anchor aria-hidden=true href=#animation-api>#</a></h2><p>This is the core engine powering Compose animation. API has nothing to do with compose though as this is completely decoupled from compose and essentially you can consume this and come up with your own Animation system. Compose Animation APIs we will see, are built on top of this API.</p><p>Animation API is stateless. That means it doesn‚Äôt know anything about the current state of animation. It is not responsible for managing things like changing the target if the user interrupts the animation or tracking the current progress of the animation. These are the responsibilities of high-level APIs.</p><p>This API is a function of time. All it knows is given the playtime of animation what would be the value of animation at a given playtime. A perfect analogy for this would be scrabbling through video playback. You can jump to a specific time in the video and it will give you a frame at that timestamp.</p><p>Let‚Äôs see one example to understand this better. Going back to the same example we saw earlier. We are animating a value from 0 to 1 for 500 ms. If you feed 250 ms to Animation API it will give you the value of animation at that playtime.</p><figure><img loading=lazy src=images/animation_playtime_blackbox.svg></figure><p>So Animation API is essentially a function of time. Given a playtime what would be value at that playtime?</p><figure><img loading=lazy src=images/function_of_playtime.png></figure><p>Here is the abstraction.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-kotlin data-lang=kotlin><span class=line><span class=cl><span class=k>interface</span> <span class=nc>Animation</span><span class=p>&lt;</span><span class=n>T</span><span class=p>,</span> <span class=n>V</span> <span class=p>:</span> <span class=n>AnimationVector</span><span class=p>&gt;</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=p>.</span>
</span></span><span class=line><span class=cl>    <span class=p>.</span>
</span></span><span class=line><span class=cl>    <span class=p>.</span>
</span></span><span class=line><span class=cl>    <span class=c1>// Returns the value of the animation at the given play time
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>fun</span> <span class=nf>getValueFromNanos</span><span class=p>(</span><span class=n>playTimeNanos</span><span class=p>:</span> <span class=n>Long</span><span class=p>):</span> <span class=n>T</span>
</span></span><span class=line><span class=cl>    <span class=p>.</span>
</span></span><span class=line><span class=cl>    <span class=p>.</span>
</span></span><span class=line><span class=cl>    <span class=p>.</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Looking at the abstraction we can see it is a type agnostic. It can animate any value you feed in. That‚Äôs why there is <code>AnimationVector</code>. Which is the type that animation API deals with. It cannot operate on the type of values you provide. For example, If you are animating Color it will convert Color into something called <code>AnimationVector3D(v1: Float, v2: Float, v3: Float)</code> as Color has three dimensions (RGB). Animating Color will then result in animating RGB values.</p><p>Notice returned value is of your original type. It converts back calculated values from AnimationVector to the type you feed in. There for, you need to also provide <code>TwoWayConverter</code> if you are animating your custom type.</p><p>Looking at the abstraction it is quit straightforward.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-kotlin data-lang=kotlin><span class=line><span class=cl><span class=cm>/**
</span></span></span><span class=line><span class=cl><span class=cm> * [TwoWayConverter] class contains the definition on how to convert from an arbitrary type [T] to a
</span></span></span><span class=line><span class=cl><span class=cm> * [AnimationVector], and convert the [AnimationVector] back to the type [T]. This allows animations
</span></span></span><span class=line><span class=cl><span class=cm> * to run on any type of objects, e.g. position, rectangle, color, etc.
</span></span></span><span class=line><span class=cl><span class=cm> */</span>
</span></span><span class=line><span class=cl><span class=k>public</span> <span class=k>interface</span> <span class=nc>TwoWayConverter</span><span class=p>&lt;</span><span class=n>T</span><span class=p>,</span> <span class=n>V</span> <span class=p>:</span> <span class=n>AnimationVector</span><span class=p>&gt;</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=cm>/**
</span></span></span><span class=line><span class=cl><span class=cm>     * Defines how a type [T] should be converted to a Vector type (i.e. [AnimationVector1D],
</span></span></span><span class=line><span class=cl><span class=cm>     * [AnimationVector2D], [AnimationVector3D] or [AnimationVector4D], depends on the dimensions of
</span></span></span><span class=line><span class=cl><span class=cm>     * type T).
</span></span></span><span class=line><span class=cl><span class=cm>     */</span>
</span></span><span class=line><span class=cl>    <span class=k>public</span> <span class=k>val</span> <span class=py>convertToVector</span><span class=p>:</span> <span class=p>(</span><span class=n>T</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>V</span>
</span></span><span class=line><span class=cl>    <span class=cm>/**
</span></span></span><span class=line><span class=cl><span class=cm>     * Defines how to convert a Vector type (i.e. [AnimationVector1D], [AnimationVector2D],
</span></span></span><span class=line><span class=cl><span class=cm>     * [AnimationVector3D] or [AnimationVector4D], depends on the dimensions of type T) back to type
</span></span></span><span class=line><span class=cl><span class=cm>     * [T].
</span></span></span><span class=line><span class=cl><span class=cm>     */</span>
</span></span><span class=line><span class=cl>    <span class=k>public</span> <span class=k>val</span> <span class=py>convertFromVector</span><span class=p>:</span> <span class=p>(</span><span class=n>V</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>T</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Coming back to Animation API, There are two implementations of this. <code>TargetBasedAnimation</code> and <code>DecayAnimation</code>.</p><h3 id=targetbasedanimation>TargetBasedAnimation<a hidden class=anchor aria-hidden=true href=#targetbasedanimation>#</a></h3><p><code>TargetBasedAnimation</code> animates values to a specific target. If the target is known, in the above example it was 1. As playtime approaches the duration of animation so does the value approaching the target.</p><h3 id=decayanimation>DecayAnimation<a hidden class=anchor aria-hidden=true href=#decayanimation>#</a></h3><p><code>DecayAnimation</code> animates values where the target is unknown. For example, based on initial fling velocity if we want to move something we don‚Äôt know where it will end up once velocity becomes zero. Animation here decay over a time.</p><p>Let‚Äôs zoom in further. How does Animation API calculate the value at a given playtime? ü§î</p><figure><img loading=lazy src=images/function_of_function_of_playtime.png></figure><p>Internally it delegates to AnimationSpec. So real hero doing heavy lifting is not Animation but AnimationSpec. I kinda lied that Animation API powers Compose Animation. Ultimately complex math is in AnimationSpec. Brace yourself for some scary Math! üëª</p><p>For the scope of this blog, I am going to cover <code>FloatTweenSpec</code>. This is one of the specs you get out of the box. Before we jump into implementation details, let&rsquo;s first understand the key concept of <code>FloatTweenSpec</code></p><ol><li>Duration: This specifies how long the animation will take to complete, typically in milliseconds (ms).</li><li>Easing: It controls the rate of change of the animation. Common easing functions include linear interpolation, deceleration, acceleration etc.</li><li>Delay: You can introduce a delay before the animation starts, allowing more control over when the animation begins.</li><li>Interpolation: At the core of <code>FloatTweenSpec</code> is the interpolation of values from the start to the end over the animation&rsquo;s duration.</li></ol><p>Let&rsquo;s see the implementation details and see how it calculates the value.</p><blockquote><p><em>This is not full implementation. I trimmed this to focus on parts we are interested in. You can check full implementation <a href="https://cs.android.com/androidx/platform/frameworks/support/+/androidx-main:compose/animation/animation-core/src/commonMain/kotlin/androidx/compose/animation/core/FloatAnimationSpec.kt;l=201?q=TweenSpec&amp;ss=androidx%2Fplatform%2Fframeworks%2Fsupport">here</a>.</em></p></blockquote><div class=highlight><pre tabindex=0 class=chroma><code class=language-kotlin data-lang=kotlin><span class=line><span class=cl><span class=k>public</span> <span class=k>class</span> <span class=nc>FloatTweenSpec</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=k>public</span> <span class=k>val</span> <span class=py>duration</span><span class=p>:</span> <span class=n>Int</span> <span class=p>=</span> <span class=n>DefaultDurationMillis</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=k>public</span> <span class=k>val</span> <span class=py>delay</span><span class=p>:</span> <span class=n>Int</span> <span class=p>=</span> <span class=m>0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=k>private</span> <span class=k>val</span> <span class=py>easing</span><span class=p>:</span> <span class=n>Easing</span> <span class=p>=</span> <span class=n>FastOutSlowInEasing</span>
</span></span><span class=line><span class=cl><span class=p>)</span> <span class=p>:</span> <span class=n>FloatAnimationSpec</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=p>.</span>
</span></span><span class=line><span class=cl>    <span class=p>.</span>
</span></span><span class=line><span class=cl>    <span class=p>.</span>
</span></span><span class=line><span class=cl>    <span class=k>override</span> <span class=k>fun</span> <span class=nf>getValueFromNanos</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>playTimeNanos</span><span class=p>:</span> <span class=n>Long</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>initialValue</span><span class=p>:</span> <span class=n>Float</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>targetValue</span><span class=p>:</span> <span class=n>Float</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>initialVelocity</span><span class=p>:</span> <span class=n>Float</span>
</span></span><span class=line><span class=cl>    <span class=p>):</span> <span class=n>Float</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>val</span> <span class=py>clampedPlayTimeNanos</span> <span class=p>=</span> <span class=n>clampPlayTimeNanos</span><span class=p>(</span><span class=n>playTimeNanos</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>val</span> <span class=py>rawFraction</span> <span class=p>=</span> <span class=k>if</span> <span class=p>(</span><span class=n>duration</span> <span class=o>==</span> <span class=m>0</span><span class=p>)</span> <span class=m>1f</span> <span class=k>else</span> <span class=n>clampedPlayTimeNanos</span> <span class=p>/</span> <span class=n>durationNanos</span><span class=p>.</span><span class=n>toFloat</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>val</span> <span class=py>fraction</span> <span class=p>=</span> <span class=n>easing</span><span class=p>.</span><span class=n>transform</span><span class=p>(</span><span class=n>rawFraction</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>lerp</span><span class=p>(</span><span class=n>initialValue</span><span class=p>,</span> <span class=n>targetValue</span><span class=p>,</span> <span class=n>fraction</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>.</span>
</span></span><span class=line><span class=cl>    <span class=p>.</span>
</span></span><span class=line><span class=cl>    <span class=p>.</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><ol><li>It first calculates how much time has passed (playTime - delayNanos), and clamps this value between 0 and durationNanos. <code>clampedPlayTimeNanos</code> function above, exactly does that.</li><li>The next step is to compute the fraction of the animation&rsquo;s progress (<code>rawFraction = clampedPlayTimeNanos / durationNanos</code>). If provided duration is zero then the animation would stop immediately with target value.</li><li>Then, it applies the easing function (<code>fraction = easing.transform(rawFraction)</code>) to modify the fraction according to the specified easing curve.</li><li>Finally, it interpolates between the start and end values using the <code>lerp()</code> function, which performs a linear interpolation between the two values based on the eased fraction.</li></ol><p>To boildown this, easing functions convert raw fraction of animation progress into a fraction that follows a specific curve. You can read about this in more detail <a href=https://medium.com/androiddevelopers/easing-in-to-easing-curves-in-jetpack-compose-d72893eeeb4d>here</a>.</p><p>Following are some more built-in specs that you might want to check out. I will leave that up to you to explore üôÇ</p><ul><li><code>SpringSpec</code></li><li><code>RepeatableSpec</code></li><li><code>InfiniteRepeatableSpec</code></li></ul><h2 id=parting-thoughts>Parting Thoughts<a hidden class=anchor aria-hidden=true href=#parting-thoughts>#</a></h2><p>That‚Äôs all for this part. I know this would be a bit overwhelming. I would suggest following this blog along with Animation API open within Android Studio or <a href=cs.android.com>cs.android.com</a>.</p><p>So far we have just seen a blackbox which is function of time powering Compose animation. I hope this sets a nice foundation for the next part. In the next part we will see how Compose Animation API leverage this blackbox. Stay tuned!</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://sagarviradiya.dev/tags/compose/>Compose</a></li><li><a href=https://sagarviradiya.dev/tags/animation/>Animation</a></li></ul><nav class=paginav><a class=next href=https://sagarviradiya.dev/posts/automating-baseline-profile/><span class=title>Next ¬ª</span><br><span>Automating Baseline Profile end-to-end on CI</span></a></nav></footer><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//sagarviradiya-dev.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></article></main><footer class=footer><span>&copy; 2024 <a href=https://sagarviradiya.dev/>Sagar's Blog</a></span> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>